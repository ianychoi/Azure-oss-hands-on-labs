{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairlearn 오픈소스 패키지를 사용한 ML 모델 fairness 확인 + 애저 머신러닝 서비스와의 연동\n",
    "\n",
    "- 참고 문서\n",
    " - Docs (영문): https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml\n",
    "   - Docs (한글, 기계 번역): https://docs.microsoft.com/ko-kr/azure/machine-learning/how-to-machine-learning-fairness-aml\n",
    " - Fairlearn 퀵스타트 (영문): https://fairlearn.github.io/v0.5.0/quickstart.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 예제 모델 학습\n",
    "\n",
    "- 데이터셋: OpenML에 업로드된 성인 인구조사 활용 (URL: https://www.openml.org/d/1590)\n",
    "- 모델: DecisionTreeClassifier를 사용하여 연간 소득이 > 5만 달러 여부를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1611320893558
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# 인구조사 데이터셋 불러오기\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "# 성별 및 인종과 같이 민감한 feature를 모델 트레이닝에서 제외\n",
    "X_raw = data.data\n",
    "y_true = (data.target == \">50K\") * 1\n",
    "A = X_raw[[\"race\", \"sex\"]]\n",
    "X_raw = pd.get_dummies(X_raw.drop(labels=['sex', 'race'],axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      32650\n",
       "Female    16192\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성별(sex) 데이터셋 확인\n",
    "sex = data.data['sex']\n",
    "sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                 41762\n",
       "Black                  4685\n",
       "Asian-Pac-Islander     1519\n",
       "Amer-Indian-Eskimo      470\n",
       "Other                   406\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인종(race) 데이터셋 확인\n",
    "race = data.data['race']\n",
    "race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 \"train\" (트레이닝) 및 \"test\" (테스트) 셋으로 분리\n",
    "(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n",
    "    X_raw, y_true, A, test_size=0.3, random_state=12345, stratify=y_true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure indices are aligned between X, y and A,\n",
    "# after all the slicing and splitting of DataFrames\n",
    "# and Series\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "A_train = A_train.reset_index(drop=True)\n",
    "A_test = A_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 모델에 대한 메트릭 확인\n",
    "- Docs (영문): https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/evaluate-model#metrics-for-classification-models\n",
    "- Docs (한글, 기계번역): https://docs.microsoft.com/ko-kr/azure/machine-learning/algorithm-module-reference/evaluate-model#metrics-for-classification-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.840\n",
      "Precision: 0.723\n",
      "Recall: 0.535\n",
      "F1 score: 0.615\n",
      "AUC: 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=10, max_depth=4)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tr=classifier.predict(X_test)\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred_tr))\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred_tr))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred_tr))\n",
    "print('F1 score: %.3f' % f1_score(y_test, y_pred_tr))\n",
    "print('AUC: %.3f' % roc_auc_score(y_test, y_pred_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairlearn 라이브러리: Jupyter에서 대시보드 직접 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98983608b4324b4ab5c76a68883f6c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7fd963d79e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "from fairlearn.widget import FairlearnDashboard\n",
    "FairlearnDashboard(sensitive_features=A_test, \n",
    "                   sensitive_feature_names=['Race', 'Sex'],\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"model\": y_pred_tr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 애저 머신 러닝 서비스에 연결: MLOps 연계 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 애저 머신 러닝 서비스 연결에 필요한 정보를 가져옴\n",
    "from azureml.core import Workspace, Experiment, Model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# config.json 파일에서 설정을 가져옴\n",
    "# 참고: https://docs.microsoft.com/ko-kr/azure/machine-learning/how-to-configure-environment#workspace\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering  fairness_DecisionTreeClassifier\n",
      "Registering model fairness_DecisionTreeClassifier\n",
      "Registered  fairness_DecisionTreeClassifier:2\n"
     ]
    }
   ],
   "source": [
    "# 사용한 모델 등록이 필요함 (여러 번 할 필요가 없으며, 이미 모델을 등록하였다면 기존 모델을 가져오도록 변경해야 함)\n",
    "\n",
    "# Function to register models into Azure Machine Learning\n",
    "def register_model(name, model):\n",
    "    print(\"Registering \", name)\n",
    "    model_path = \"models/{0}.pkl\".format(name)\n",
    "    joblib.dump(value=model, filename=model_path)\n",
    "    registered_model = Model.register(model_path=model_path,\n",
    "                                    model_name=name,\n",
    "                                    workspace=ws)\n",
    "    print(\"Registered \", registered_model.id)\n",
    "    return registered_model.id\n",
    "\n",
    "# Call the register_model function \n",
    "dt_classifier_id = register_model(\"fairness_DecisionTreeClassifier\", classifier)\n",
    "\n",
    "# This example code shows to use an existing registered model id\n",
    "#dt_classifier_id = Model.list(workspace=ws)[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공정성에 대한 메트릭을 미리 계산\n",
    "\n",
    "#  Create a dictionary of model(s) you want to assess for fairness \n",
    "sf = { 'Race': A_test.race, 'Sex': A_test.sex}\n",
    "ys_pred = { dt_classifier_id:y_pred_tr }\n",
    "\n",
    "from fairlearn.metrics._group_metric_set import _create_group_metric_set\n",
    "\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                    predictions=ys_pred,\n",
    "                                    sensitive_features=sf,\n",
    "                                    prediction_type='binary_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(Name: Test_Fairness_Census_Demo-testset,\n",
      "Workspace: fair-ml)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_dashboard_validation.py:Starting validation of dashboard dictionary\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_dashboard_validation.py:Validation of dashboard dictionary successful\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Validating model ids exist\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking fairness_DecisionTreeClassifier:2\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Validation of model ids complete\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Uploading y_true\n",
      "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/y_true/86b4b5c5-d0b6-49bb-ac8b-b2ff1388ccb9.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded y_true to prefix azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/y_true/86b4b5c5-d0b6-49bb-ac8b-b2ff1388ccb9.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Found 1 predictions\n",
      "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/y_pred/54cdde09-65d6-4b2a-b73a-7c08bb130834.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/y_pred/54cdde09-65d6-4b2a-b73a-7c08bb130834.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded 1 predictions\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Found {0} sensitive features\n",
      "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/sensitive_features_column/323854ea-fba8-485e-b163-f2c3c5757cfa.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded sensitive feature column to prefix azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/sensitive_features_column/323854ea-fba8-485e-b163-f2c3c5757cfa.json\n",
      "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/sensitive_features_column/cda2641c-6fc2-4a32-92a0-54029a452fdf.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded sensitive feature column to prefix azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/sensitive_features_column/cda2641c-6fc2-4a32-92a0-54029a452fdf.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded 2 sensitive features\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Uploading metrics\n",
      "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/metrics_set/67b4e55d-fdc3-47c7-820e-9481b909730c.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 0 and sensitive_feature 0\n",
      "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/metrics_set/4760bf40-8f7f-46c0-a03a-e8499d83d4e4.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 0 and sensitive_feature 1\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Creating CUF Assets\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 1641ec4380b84e01a650fb32335fa075\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 5d0233abbe52438e99aec8394420ec9a\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Fetching asset list\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating y_true\n",
      "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/y_true/86b4b5c5-d0b6-49bb-ac8b-b2ff1388ccb9.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploaded to id: 7f84dcf1-4c2b-4382-b84f-887cf315b894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating y_pred\n",
      "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/y_pred/54cdde09-65d6-4b2a-b73a-7c08bb130834.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating sensitive features\n",
      "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/sensitive_features_column/323854ea-fba8-485e-b163-f2c3c5757cfa.json\n",
      "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/sensitive_features_column/cda2641c-6fc2-4a32-92a0-54029a452fdf.json\n",
      "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating metrics\n",
      "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/metrics_set/67b4e55d-fdc3-47c7-820e-9481b909730c.json\n",
      "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/7f84dcf1-4c2b-4382-b84f-887cf315b894/metrics_set/4760bf40-8f7f-46c0-a03a-e8499d83d4e4.json\n"
     ]
    }
   ],
   "source": [
    "# 미리 계산된 공정성 메트릭을 애저 머신 러닝 서비스에 업로드\n",
    "\n",
    "from azureml.contrib.fairness import upload_dashboard_dictionary, download_dashboard_by_upload_id\n",
    "\n",
    "exp = Experiment(ws, \"Test_Fairness_Census_Demo-testset\")\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:\n",
    "    dashboard_title = \"Fairness insights of Decision Tree Classifier\"\n",
    "    # Set validate_model_ids parameter of upload_dashboard_dictionary to False if you have not registered your model(s)\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "\n",
    "    # To test the dashboard, you can download it back and ensure it contains the right information\n",
    "    downloaded_dict = download_dashboard_by_upload_id(run, upload_id)\n",
    "finally:\n",
    "    run.complete()\n",
    "    \n",
    "# 애저 머신 러닝 서비스 내에서 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
